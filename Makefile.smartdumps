# This is a smarter way of handling dumps. Provide WP_ALL_PAGES with
# the bz2 dumps you need and we will pull them, feed them to mwdumper
# and then the sql results to mysql. Then profit.

# WP_ALL_PAGES =  enwiki-20131202-pages-articles1.xml-p000000010p000010000.bz2 \
# enwiki-20131202-pages-articles2.xml-p000010002p000024999.bz2 \
# enwiki-20131202-pages-articles3.xml-p000025001p000055000.bz2 \
# enwiki-20131202-pages-articles4.xml-p000055002p000104998.bz2 \
# enwiki-20131202-pages-articles5.xml-p000105002p000184999.bz2 \
# enwiki-20131202-pages-articles6.xml-p000185003p000305000.bz2 \
# enwiki-20131202-pages-articles7.xml-p000305002p000464996.bz2 \
# enwiki-20131202-pages-articles8.xml-p000465001p000665000.bz2 \
# enwiki-20131202-pages-articles9.xml-p000665001p000925000.bz2 \
# enwiki-20131202-pages-articles10.xml-p000925001p001325000.bz2 \
# enwiki-20131202-pages-articles11.xml-p001325001p001825000.bz2 \
# enwiki-20131202-pages-articles12.xml-p001825001p002425000.bz2 \
# enwiki-20131202-pages-articles13.xml-p002425002p003124997.bz2 \
# enwiki-20131202-pages-articles14.xml-p003125001p003924999.bz2 \
# enwiki-20131202-pages-articles15.xml-p003925001p004824998.bz2 \
# enwiki-20131202-pages-articles16.xml-p004825005p006024996.bz2 \
# enwiki-20131202-pages-articles17.xml-p006025001p007524997.bz2 \
# enwiki-20131202-pages-articles18.xml-p007525004p009225000.bz2 \
# enwiki-20131202-pages-articles19.xml-p009225002p011124997.bz2 \
# enwiki-20131202-pages-articles21.xml-p013325003p015724999.bz2 \
# enwiki-20131202-pages-articles22.xml-p015725013p018225000.bz2 \
# enwiki-20131202-pages-articles23.xml-p018225004p020925000.bz2 \
# enwiki-20131202-pages-articles24.xml-p020925002p023724999.bz2 \
# enwiki-20131202-pages-articles25.xml-p023725001p026624997.bz2 \
# enwiki-20131202-pages-articles26.xml-p026625004p029624976.bz2 \
# enwiki-20131202-pages-articles27.xml-p029625017p041249406.bz2 \
# enwiki-20131202-pages-articles20.xml-p011125004p013324998.bz2
#WP_BASE_URL = http://dumps.wikimedia.org/enwiki/20131202


WP_BASE_URL = http://dumps.wikimedia.org/enwiki/20140614

WP_ALL_PAGES = enwiki-20140614-pages-meta-current1.xml-p000000010p000010000.bz2 \
enwiki-20140614-pages-meta-current2.xml-p000010001p000025000.bz2 \
enwiki-20140614-pages-meta-current3.xml-p000025001p000055000.bz2 \
enwiki-20140614-pages-meta-current4.xml-p000055002p000104998.bz2 \
enwiki-20140614-pages-meta-current5.xml-p000105001p000184999.bz2 \
enwiki-20140614-pages-meta-current6.xml-p000185003p000305000.bz2 \
enwiki-20140614-pages-meta-current7.xml-p000305002p000464997.bz2 \
enwiki-20140614-pages-meta-current8.xml-p000465001p000665000.bz2 \
enwiki-20140614-pages-meta-current9.xml-p000665001p000925000.bz2 \
enwiki-20140614-pages-meta-current10.xml-p000925001p001325000.bz2 \
enwiki-20140614-pages-meta-current11.xml-p001325001p001825000.bz2 \
enwiki-20140614-pages-meta-current12.xml-p001825001p002425000.bz2 \
enwiki-20140614-pages-meta-current13.xml-p002425001p003124998.bz2 \
enwiki-20140614-pages-meta-current14.xml-p003125001p003924999.bz2 \
enwiki-20140614-pages-meta-current15.xml-p003925001p004825000.bz2 \
enwiki-20140614-pages-meta-current16.xml-p004825002p006025000.bz2 \
enwiki-20140614-pages-meta-current17.xml-p006025001p007524997.bz2 \
enwiki-20140614-pages-meta-current18.xml-p007525002p009225000.bz2 \
enwiki-20140614-pages-meta-current19.xml-p009225001p011125000.bz2 \
enwiki-20140614-pages-meta-current20.xml-p011125001p013324998.bz2 \
enwiki-20140614-pages-meta-current21.xml-p013325001p015725000.bz2 \
enwiki-20140614-pages-meta-current22.xml-p015725003p018225000.bz2 \
enwiki-20140614-pages-meta-current23.xml-p018225001p020925000.bz2 \
enwiki-20140614-pages-meta-current24.xml-p020925002p023725000.bz2 \
enwiki-20140614-pages-meta-current25.xml-p023725001p026624999.bz2 \
enwiki-20140614-pages-meta-current26.xml-p026625002p029625000.bz2 \
enwiki-20140614-pages-meta-current27.xml-p029625001p043052726.bz2

WP_PARTS_DIR = $(DRAFTS_DIR)/wikipedia-parts

BZ_PARTS = $(WP_ALL_PAGES:%.bz2=$(WP_PARTS_DIR)/%.bz2)
SQL_PARTS = $(WP_ALL_PAGES:%.bz2=$(WP_PARTS_DIR)/%.sql)
XML_PARTS = $(WP_ALL_PAGES:%.bz2=$(WP_PARTS_DIR)/%.raw.xml)
FIXED_XML_PARTS = $(WP_ALL_PAGES:%.bz2=$(WP_PARTS_DIR)/%.fix.xml)
LOADED_MARKERS = $(WP_ALL_PAGES:%.bz2=$(WP_PARTS_DIR)/%.sql-loaded)

file-exists = $(shell ls $(1))
or-file = $(if $(call file-exists,$(1)), $(1), $(2))
# 1:original pattern, 2:replace this one if exists, 3:fallback subst, 4:fname
cond-subst = $(call or-file, $(patsubst $(1), $(2), $(4)), \
$(patsubst $(1), $(3), $(4)))


PHONY:
fixed-xml-dumps: $(FIXED_XML_PARTS)

.PHONY:
xml-dumps: $(XML_PARTS)

test-cond:
	mkdir /tmp/makefile-tests/
	touch /tmp/makefile-tests/test.bz
	@echo $(call or-file, "/tmp/makefile-tests/minicom.bz", "/tmp/makefile-tests/testies.bz") "= /tmp/makefile-tests/testies.bz"
	@echo $(call or-file, "/tmp/makefile-tests/test.bz", "/tmp/makefile-tests/testies.bz") "= /tmp/makefile-tests/test.bz"
	@echo $(call cond-subst,"%.bz","%.lo","%.sql","/tmp/makefile-tests/minicom.bz") "= /tmp/makefile-tests/minicom.sql"
	@echo $(call cond-subst, "%.bz", "%.lo", "%.sql", "/tmp/makefile-tests/test.bz") "= /tmp/makefile-tests/test.lo"
	rm -rf /tmp/makefile-tests/

ORIGINAL_XML=<mediawiki>\nbefore page 1\n<page>\nbefore title 1\n<title>title 1</title>\nafter title 1\n</page>\nafter page 1\n<page>\nbefore title 2\n<title>title 2</title>\nafter title 2\n</page>\nafter page 2\n</mediawiki>
CLEAN_XML=<mediawiki>\nbefore page 1\n<page>\nbefore title 1\n<title>title 1</title>\nafter title 1\n</page>\nafter page 1\nafter page 2\n</mediawiki>
test-page-remover: $(TOOLS_DIR)/xml-parse.sh
	echo "$(ORIGINAL_XML)" > /tmp/test.xml
	$(TOOLS_DIR)/xml-parse.sh /tmp/test.xml "title 2" > /tmp/test.clean.xml
	rm /tmp/test.xml
	@echo "### Should have this"
	cat /tmp/test.clean.xml
	@echo "### Be the same as this"
	@echo "$(CLEAN_XML)"
	[ "$(shell cat /tmp/test.clean.xml)" = "$(shell echo "$(CLEAN_XML)")" ]

	rm /tmp/test.clean.xml

.INTERMEDIATE: $(BZ_PARTS) $(SQL_PARTS)

$(WP_PARTS_DIR):
	mkdir -p $(WP_PARTS_DIR)

# For each dump make targets for their corresponding files in0
# WP_PARTS_DIR
$(BZ_PARTS): | $(WP_PARTS_DIR)
	echo "Dowloading: $@..."
	wget -nv $(subst $(WP_PARTS_DIR), $(WP_BASE_URL), $@) -O $@
	touch $@

DUMP_CMD_xml = java -jar $(MWDUMPER_JAR)  $(MWDUMPER_ARGS) --format=xml
DUMP_CMD_sql = java -jar $(MWDUMPER_JAR)  $(MWDUMPER_ARGS)  --format=sql:1.5
DUMP_CMD = $(DUMP_CMD_sql)

err_file=$(DRAFTS_DIR)/errored_articles

$(TOOLS_DIR)/xml-parse.sh: $(DATA_DIR)/xml-parse.sh
	cp $< $@

# Watch out now. If a quiet command fails, the stderr is swallowed. If
# this turns out to be problem make a ring buffer of lines. to keep
# the last lines of output.
REV_COUNT_FEEDBACK=50
quiet_filter=awk 'BEGIN{cnt=0; tot=0; print "Will be printing once every $(REV_COUNT_FEEDBACK) lines (controlled by REV_COUNT_FEEDBACK)"} {cnt=cnt+1} (cnt >= $(REV_COUNT_FEEDBACK)){tot=tot+cnt; print "[Total lines: " tot " ] " $$0; cnt=0}'
last_article_filter=tac | grep -m 1 -F "<title>" | sed  's/ *<title>\(.*\)<\/title>/\1/'


# Quiet err will sample the stderr and also show the last 20 lines
fifo1 := $(shell mktemp --dry-run)
fifo2 := $(shell mktemp --dry-run)
quiet-err = (ret=0; mkfifo $(fifo1) && mkfifo $(fifo2) && \
	(cat $(fifo1) | tee $(fifo2) | $(quiet_filter) &  reader_pid1=$$! && \
	cat $(fifo2) | tail -20 & reader_pid2=$$! && \
	echo "Running command, readers on pids $$reader_pid1, $$reader_pid2"; \
	( $1 ) 2>$(fifo1); export ret=$$?; \
	wait; \
	rm -rf $(fifo1) $(fifo2); exit $$ret))

test-quiet-err:
	@echo "If you can see this you are fine"
	! $(call  quiet-err, awk 'BEGIN{for (i=0;i<500; i++) print i}' >&2; exit 55);

$(SQL_PARTS): $$(patsubst %.sql,%.fix.xml,$$@) | $(TOOLS_DIR)/xml-parse.sh $(MWDUMPER_JAR)
	@echo "Generating $@"
	if ! ($(call quiet-err,$(DUMP_CMD) $< > $@ ) || (echo "FAIL" && false)); then \
		$(call quiet-err,$(DUMP_CMD_xml) $< | $(last_article_filter) >> $(err_file)) && \
		echo "The errored article is $$(cat $(err_file) | tail -1) ( $(err_file) ). Fixing... (time: $$(date))" &&  \
		rm -rf $@ && \
		$(TOOLS_DIR)/xml-parse.sh $< "$$(cat $(err_file) | tail -1)" > "$<.mwfix" && \
		$(call quiet-err,$(DUMP_CMD) $<.wmfix > $@) && \
		echo "Finished second pass over $< afer removing $$(cat $(err_file) | tail -1)"; \
	fi

show-error-file:
	@echo $(err_file)

# To avoid recursion i will assume that only one article is problematic.

# You can use mwdumber-command-sql or mwdumper-command-xml to get the
# respective commands that should create dumps of those formats. Use
# the xml one to investigate where mwdumper breaks.
.PHONY:
mwdumper-command-%:
	@echo "$(DUMP_CMD_$*) IN_XML_FILE > OUT_$*_FILE "

# Each *.sql-loaded file that exists means that the corresponding .sql
# file was loaded already in the db.
.SECONDEXPANSION:
$(LOADED_MARKERS): $$(patsubst %.sql-loaded,%.sql,$$@) | bmw-run $(MYSQL)
	@echo "loading: $(@:.sql-loaded=.sql)..."
	(echo "SET AUTOCOMMIT = 0; SET FOREIGN_KEY_CHECKS=0;"; \
		cat $(@:.sql-loaded=.sql); \
		echo "SET FOREIGN_KEY_CHECKS = 1;COMMIT;SET AUTOCOMMIT = 1;" \
	) | $(MYSQL_CMD) && \
	touch $@


## FIXING UTF8
# It turns out part 20 has some utf8 problems. Here are some targets
# to fix that.

%.raw.xml: %.bz2
	bzcat -dv $< > $@

# Note: This destroys %.raw.xml
%.fix.xml: %.raw.xml | $(DATA_DIR)/utf-fixer
	$(DATA_DIR)/utf-fixer  $<
	mv $< $@

fix-%.bz2: $$(patsubst fix-%.bz2,%.fix.xml,$$@)

# Load all sql files.
.PHONY:
sql-load-parts: $(LOADED_MARKERS)

.PHONY:
clean-sql-parts:
	rm -rf $(SQL_PARTS)

# Create all sql dumps.
.PHONY:
sql-dump-parts: $(SQL_PARTS)
