# This is a smarter way of handling dumps. Provide WP_ALL_PAGES with
# the bz2 dumps you need and we will pull them, feed them to mwdumper
# and then the sql results to mysql. Then profit.

# WP_ALL_PAGES =  enwiki-20131202-pages-articles1.xml-p000000010p000010000.bz2 \
# enwiki-20131202-pages-articles2.xml-p000010002p000024999.bz2 \
# enwiki-20131202-pages-articles3.xml-p000025001p000055000.bz2 \
# enwiki-20131202-pages-articles4.xml-p000055002p000104998.bz2 \
# enwiki-20131202-pages-articles5.xml-p000105002p000184999.bz2 \
# enwiki-20131202-pages-articles6.xml-p000185003p000305000.bz2 \
# enwiki-20131202-pages-articles7.xml-p000305002p000464996.bz2 \
# enwiki-20131202-pages-articles8.xml-p000465001p000665000.bz2 \
# enwiki-20131202-pages-articles9.xml-p000665001p000925000.bz2 \
# enwiki-20131202-pages-articles10.xml-p000925001p001325000.bz2 \
# enwiki-20131202-pages-articles11.xml-p001325001p001825000.bz2 \
# enwiki-20131202-pages-articles12.xml-p001825001p002425000.bz2 \
# enwiki-20131202-pages-articles13.xml-p002425002p003124997.bz2 \
# enwiki-20131202-pages-articles14.xml-p003125001p003924999.bz2 \
# enwiki-20131202-pages-articles15.xml-p003925001p004824998.bz2 \
# enwiki-20131202-pages-articles16.xml-p004825005p006024996.bz2 \
# enwiki-20131202-pages-articles17.xml-p006025001p007524997.bz2 \
# enwiki-20131202-pages-articles18.xml-p007525004p009225000.bz2 \
# enwiki-20131202-pages-articles19.xml-p009225002p011124997.bz2 \
# enwiki-20131202-pages-articles21.xml-p013325003p015724999.bz2 \
# enwiki-20131202-pages-articles22.xml-p015725013p018225000.bz2 \
# enwiki-20131202-pages-articles23.xml-p018225004p020925000.bz2 \
# enwiki-20131202-pages-articles24.xml-p020925002p023724999.bz2 \
# enwiki-20131202-pages-articles25.xml-p023725001p026624997.bz2 \
# enwiki-20131202-pages-articles26.xml-p026625004p029624976.bz2 \
# enwiki-20131202-pages-articles27.xml-p029625017p041249406.bz2 \
# enwiki-20131202-pages-articles20.xml-p011125004p013324998.bz2
#WP_BASE_URL = http://dumps.wikimedia.org/enwiki/20131202


#WP_BASE_URL = http://dumps.wikimedia.org/enwiki/20140614
# WP_ALL_PAGES = enwiki-20140614-pages-meta-current1.xml-p000000010p000010000.bz2 \
# enwiki-20140614-pages-meta-current2.xml-p000010001p000025000.bz2 \
# enwiki-20140614-pages-meta-current3.xml-p000025001p000055000.bz2 \
# enwiki-20140614-pages-meta-current4.xml-p000055002p000104998.bz2 \
# enwiki-20140614-pages-meta-current5.xml-p000105001p000184999.bz2 \
# enwiki-20140614-pages-meta-current6.xml-p000185003p000305000.bz2 \
# enwiki-20140614-pages-meta-current7.xml-p000305002p000464997.bz2 \
# enwiki-20140614-pages-meta-current8.xml-p000465001p000665000.bz2 \
# enwiki-20140614-pages-meta-current9.xml-p000665001p000925000.bz2 \
# enwiki-20140614-pages-meta-current10.xml-p000925001p001325000.bz2 \
# enwiki-20140614-pages-meta-current11.xml-p001325001p001825000.bz2 \
# enwiki-20140614-pages-meta-current12.xml-p001825001p002425000.bz2 \
# enwiki-20140614-pages-meta-current13.xml-p002425001p003124998.bz2 \
# enwiki-20140614-pages-meta-current14.xml-p003125001p003924999.bz2 \
# enwiki-20140614-pages-meta-current15.xml-p003925001p004825000.bz2 \
# enwiki-20140614-pages-meta-current16.xml-p004825002p006025000.bz2 \
# enwiki-20140614-pages-meta-current17.xml-p006025001p007524997.bz2 \
# enwiki-20140614-pages-meta-current18.xml-p007525002p009225000.bz2 \
# enwiki-20140614-pages-meta-current19.xml-p009225001p011125000.bz2 \
# enwiki-20140614-pages-meta-current20.xml-p011125001p013324998.bz2 \
# enwiki-20140614-pages-meta-current21.xml-p013325001p015725000.bz2 \
# enwiki-20140614-pages-meta-current22.xml-p015725003p018225000.bz2 \
# enwiki-20140614-pages-meta-current23.xml-p018225001p020925000.bz2 \
# enwiki-20140614-pages-meta-current24.xml-p020925002p023725000.bz2 \
# enwiki-20140614-pages-meta-current25.xml-p023725001p026624999.bz2 \
# enwiki-20140614-pages-meta-current26.xml-p026625002p029625000.bz2 \
# enwiki-20140614-pages-meta-current27.xml-p029625001p043052726.bz2


WP_BASE_URL = http://wikimedia.wansec.com/archive/enwiki/20080103/
WP_ALL_PAGES = enwiki-20080103-pages-articles.xml.bz2

WP_PARTS_DIR = $(DRAFTS_DIR)/wikipedia-parts

BZ_PARTS = $(WP_ALL_PAGES:%.bz2=$(WP_PARTS_DIR)/%.bz2)
SQL_PARTS =  $(WP_ALL_PAGES:%.bz2=$(WP_PARTS_DIR)/%.sql)
XML_PARTS = $(WP_ALL_PAGES:%.bz2=$(WP_PARTS_DIR)/%.raw.xml)
FIXED_XML_PARTS = $(WP_ALL_PAGES:%.bz2=$(WP_PARTS_DIR)/%.fix.xml)
LOADED_MARKERS = $(SQL_PARTS:%.sql=%.sql-loaded)

file-exists = $(shell ls $(1))
or-file = $(if $(call file-exists,$(1)), $(1), $(2))
# 1:original pattern, 2:replace this one if exists, 3:fallback subst, 4:fname
cond-subst = $(call or-file, $(patsubst $(1), $(2), $(4)), \
$(patsubst $(1), $(3), $(4)))

# This is a 0byte dummy to help with the time estimation.
$(WP_PARTS_DIR)/dummy.sql:
	touch $@

PHONY:
fixed-xml-dumps: $(FIXED_XML_PARTS)

.PHONY:
xml-dumps: $(XML_PARTS)

test-cond:
	mkdir /tmp/makefile-tests/
	touch /tmp/makefile-tests/test.bz
	@echo $(call or-file, "/tmp/makefile-tests/minicom.bz", "/tmp/makefile-tests/testies.bz") "= /tmp/makefile-tests/testies.bz"
	@echo $(call or-file, "/tmp/makefile-tests/test.bz", "/tmp/makefile-tests/testies.bz") "= /tmp/makefile-tests/test.bz"
	@echo $(call cond-subst,"%.bz","%.lo","%.sql","/tmp/makefile-tests/minicom.bz") "= /tmp/makefile-tests/minicom.sql"
	@echo $(call cond-subst, "%.bz", "%.lo", "%.sql", "/tmp/makefile-tests/test.bz") "= /tmp/makefile-tests/test.lo"
	rm -rf /tmp/makefile-tests/

ORIGINAL_XML=<mediawiki>\nbefore page 1\n<page>\nbefore title 1\n<title>title 1</title>\nafter title 1\n</page>\nafter page 1\n<page>\nbefore title 2\n<title>title 2</title>\nafter title 2\n</page>\nafter page 2\n</mediawiki>
CLEAN_XML=<mediawiki>\nbefore page 1\n<page>\nbefore title 1\n<title>title 1</title>\nafter title 1\n</page>\nafter page 1\nafter page 2\n</mediawiki>
test-page-remover: $(TOOLS_DIR)/xml-parse.sh
	echo "$(ORIGINAL_XML)" > /tmp/test.xml
	$(TOOLS_DIR)/xml-parse.sh /tmp/test.xml "title 2" > /tmp/test.clean.xml
	rm /tmp/test.xml
	@echo "### Should have this"
	cat /tmp/test.clean.xml
	@echo "### Be the same as this"
	@echo "$(CLEAN_XML)"
	[ "$(shell cat /tmp/test.clean.xml)" = "$(shell echo "$(CLEAN_XML)")" ]

	rm /tmp/test.clean.xml

.INTERMEDIATE: $(BZ_PARTS) $(SQL_PARTS)

$(WP_PARTS_DIR):
	mkdir -p $(WP_PARTS_DIR)

# For each dump make targets for their corresponding files in0
# WP_PARTS_DIR
$(BZ_PARTS): | $(WP_PARTS_DIR)
	echo "Dowloading: $@..."
	wget -nv $(subst $(WP_PARTS_DIR), $(WP_BASE_URL), $@) -O $@
	touch $@ # Make sure the timestamp is the download time.

DUMP_CMD_xml = java -jar $(MWDUMPER_JAR)  $(MWDUMPER_ARGS) --format=xml
DUMP_CMD_sql = java -jar $(MWDUMPER_JAR)  $(MWDUMPER_ARGS)  --format=sql:1.5
DUMP_CMD = $(DUMP_CMD_sql)

err_file=$(DRAFTS_DIR)/errored_articles

$(TOOLS_DIR)/xml-parse.sh: $(DATA_DIR)/xml-parse.sh | $(TOOLS_DIR)
	cp $< $@

# Watch out now. If a quiet command fails, the stderr is swallowed. If
# this turns out to be problem make a ring buffer of lines. to keep
# the last lines of output.
REV_COUNT_FEEDBACK=50
quiet_filter=awk 'BEGIN{cnt=0; tot=0; print "Will be printing once every $(REV_COUNT_FEEDBACK) lines (controlled by REV_COUNT_FEEDBACK)"} {cnt=cnt+1} (cnt >= $(REV_COUNT_FEEDBACK)){tot=tot+cnt; print "[Total lines: " tot " ] " $$0; cnt=0}'
last_article_filter=tac | grep -m 1 -F "<title>" | sed  's/ *<title>\(.*\)<\/title>/\1/'


# Quiet err will sample the stderr and also show the last 20 lines
fifo1 := $(shell mktemp --dry-run)
fifo2 := $(shell mktemp --dry-run)
quiet-err = (ret=0; mkfifo $(fifo1) && mkfifo $(fifo2) && \
	(cat $(fifo1) | tee $(fifo2) | $(quiet_filter) &  reader_pid1=$$! && \
	cat $(fifo2) | tail -20 & reader_pid2=$$! && \
	echo "Running command, readers on pids $$reader_pid1, $$reader_pid2"; \
	( $1 ) 2>$(fifo1); export ret=$$?; \
	wait; \
	rm -rf $(fifo1) $(fifo2); exit $$ret))

test-quiet-err:
	@echo "If you can see this you are fine"
	! $(call  quiet-err, awk 'BEGIN{for (i=0;i<500; i++) print i}' >&2; exit 55);

$(SQL_PARTS): $$(patsubst %.sql,%.fix.xml,$$@) | $(TOOLS_DIR)/xml-parse.sh $(MWDUMPER_JAR)
	@echo "Generating $@"
	if ! ($(call quiet-err,$(DUMP_CMD) $< > $@ ) || (echo "FAIL" && false)); then \
		$(call quiet-err,$(DUMP_CMD_xml) $< | $(last_article_filter) >> $(err_file)) && \
		echo "The errored article is $$(cat $(err_file) | tail -1) ( $(err_file) ). Fixing... (time: $$(date))" &&  \
		rm -rf $@ && \
		$(TOOLS_DIR)/xml-parse.sh $< "$$(cat $(err_file) | tail -1)" > /tmp/$$(basename $<.mw_fix) && \
		$(call quiet-err,$(DUMP_CMD) /tmp/$$(basename $<.mw_fix) > $@) && \
		echo "Finished second pass over $< afer removing $$(cat $(err_file) | tail -1)"; \
	fi

show-error-file:
	@echo $(err_file)

# To avoid recursion i will assume that only one article is problematic.

# You can use mwdumber-command-sql or mwdumper-command-xml to get the
# respective commands that should create dumps of those formats. Use
# the xml one to investigate where mwdumper breaks.
.PHONY:
mwdumper-command-%:
	@echo "$(DUMP_CMD_$*) IN_XML_FILE > OUT_$*_FILE "

# Each *.sql-loaded file that exists means that the corresponding .sql
# file was loaded already in the db.
SQL_NOTIFY_INTERVAL=500
.SECONDEXPANSION:
$(LOADED_MARKERS): $$(patsubst %.sql-loaded,%.sql,$$@) | bmw-run $(MYSQL)
	@echo "loading: $(@:.sql-loaded=.sql)..."
	/bin/bash -c '\
		( echo "SET AUTOCOMMIT = 0; SET FOREIGN_KEY_CHECKS=0;" && \
			cat $(@:.sql-loaded=.sql) && \
			echo "SET FOREIGN_KEY_CHECKS=1;COMMIT;SET AUTOCOMMIT=1;") | \
		tee >( $(MYSQL_CMD) ) | \
		awk \'(NR % $(SQL_NOTIFY_INTERVAL) == 0){print "[" systime() "] Loaded " NR " sql cmds"}\'' && \
	touch $@

## FIXING UTF8
# It turns out part 20 has some utf8 problems. Here are some targets
# to fix that.

%.raw.xml: %.bz2
	bzcat -dv $< > $@

# Note: This destroys %.raw.xml
%.fix.xml: %.raw.xml | $(DATA_DIR)/utf-fixer
	$(DATA_DIR)/utf-fixer  $<
	mv $< $@

fix-%.bz2: $$(patsubst fix-%.bz2,%.fix.xml,$$@)

# Load all sql files.
.PHONY:
sql-load-parts: $(WP_PARTS_DIR)/dummy.sql $(LOADED_MARKERS)

.PHONY:
clean-sql-parts:
	rm -rf $(SQL_PARTS)

# Create all sql dumps.
.PHONY:
sql-dump-parts: $(SQL_PARTS)

$(TOOLS_DIR)/stats.py: $(DATA_DIR)/stats.py
	cp $< $@

LOAD_DUMP_TIMES_CMD=(for i in $(LOADED_MARKERS); do \
	[ -f $$i ] && echo $$(stat -c '%X' $$i 2> /dev/null) $$(stat -c '%s' $${i%-loaded}); done | \
	sort | awk '(NR==1){stime=$$1; totsize=0} {totsize+=$$2} {print totsize " " $$1-stime}' )

TOTAL_SQL_SIZE=$(shell sum=0; for i in $(SQL_PARTS); do sum=$$(($$sum+$$(stat -c '%s' $${i%-loaded}))); done; echo $$sum)
SQL_PARTS_COUNT=$(shell for i in $(SQL_PARTS); do echo $$i; done | wc -l)

TIME_ESTIMATE_CMD=$(LOAD_DUMP_TIMES_CMD) | python $< estimate $(TOTAL_SQL_SIZE)

export MPLCONFIGDIR=$(DRAFTS_DIR)
.PHONY:
show-estimated-time: $(TOOLS_DIR)/stats.py
	$(TIME_ESTIMATE_CMD)


.PHONY:
test-stats: $(TOOLS_DIR)/stats.py
	echo "1 2" | python $< estimate
	echo -n "0\n1\n2\n" | python $< estimate 10
	echo -n "1 1\n2 2\n3 3\n" | python $< estimate 10

.PHONY:
test-dump-times:
	$(LOAD_DUMP_TIMES_CMD)

count-pages-in-files=(for i in $1; do grep -F "<page>" $$i; done | wc -l)
.PHONY:
test-articles-number: $(FIXED_XML_PARTS) $(XML_PARTS) $(LOADED_MARKERS)
	@echo "XML dumps page count:"
	$(call count-pages-in-files, $(XML_PARTS))
	@echo "Fixed XML dumps page count:"
	$(call count-pages-in-files, $(FIXED_XML_PARTS))
	@echo "Database page count:"
	echo "select count(*) from page" | $(MYSQL_CMD)

.PHONY:
show-innodb-stats:
	echo $$(echo "show engine innodb status" | $(MYSQL_ROOT_CMD))

.PHONY:
sql-clean: mysql-clear
	rm -rf $(LOADED_MARKERS)


sql_loaded_so_far=$(shell ls $(WP_PARTS_DIR)/*-loaded | wc -l)
.PHONY:
show-sql-loaded-files-number:
	@echo $(sql_loaded_so_far)

.PHONY:
show-sql-load-percentage: $(FIXED_XML_PARTS)
	for i in $(FIXED_XML_PARTS); do stat -c '%X %s %n' $$i; done | sort | awk 'BEGIN{sum=0; tot=0} (NR < $(sql_loaded_so_far)+1){sum+=$$2; print "*"} { print; tot+=$$2} END{print sum "/" tot" = " sum/tot }'
